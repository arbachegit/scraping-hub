name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run linting
        run: |
          pip install ruff
          ruff check .

      - name: Run type checking
        continue-on-error: true  # Type hints are advisory, not blocking
        run: |
          pip install mypy
          mypy src --ignore-missing-imports || echo "Type checking has warnings (non-blocking)"

      - name: Run tests
        run: |
          pytest tests/ -v --cov=src --cov-report=xml

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: false

  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Increment version
        run: |
          NEW_VERSION=$(python scripts/version.py --deploy)
          echo "VERSION=$NEW_VERSION" >> $GITHUB_ENV
          echo "New version: $NEW_VERSION"

      - name: Commit version bump
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add VERSION
          git diff --staged --quiet || git commit -m "chore: bump version to ${{ env.VERSION }} [skip ci]"
          git push || echo "Nothing to push"

      - name: Deploy to server
        uses: appleboy/ssh-action@master
        env:
          APOLLO_API_KEY: ${{ secrets.APOLLO_API_KEY }}
        with:
          host: ${{ secrets.DO_HOST }}
          username: ${{ secrets.DO_USERNAME }}
          key: ${{ secrets.DO_SSH_KEY }}
          envs: APOLLO_API_KEY
          script: |
            # Find the correct project directory
            echo "=== Finding project directory ==="
            for dir in /opt/iconsai-scraping /opt/scraping-hub /var/www/iconsai-scraping /home/*/iconsai-scraping /home/*/scraping-hub; do
              if [ -d "$dir" ]; then
                echo "Found: $dir"
              fi
            done

            # Standardize on /opt/iconsai-scraping
            PROJECT_DIR="/opt/iconsai-scraping"

            # If old path exists, move it
            if [ -d "/opt/scraping-hub" ] && [ ! -d "$PROJECT_DIR" ]; then
              echo "Moving /opt/scraping-hub to $PROJECT_DIR..."
              sudo mv /opt/scraping-hub $PROJECT_DIR
            fi

            # Create directory if it doesn't exist
            if [ ! -d "$PROJECT_DIR" ]; then
              echo "Creating $PROJECT_DIR and cloning repo..."
              sudo mkdir -p $PROJECT_DIR
              sudo chown $USER:$USER $PROJECT_DIR
              cd $PROJECT_DIR
              git clone https://github.com/arbachegit/scraping-hub.git .
            else
              cd $PROJECT_DIR
            fi

            echo "Working in: $(pwd)"

            git fetch origin main
            git reset --hard origin/main

            # Update .env with Apollo API key
            if [ -n "$APOLLO_API_KEY" ]; then
              echo "=== Adding APOLLO_API_KEY to .env ==="
              if grep -q "APOLLO_API_KEY=" .env 2>/dev/null; then
                sed -i "s|APOLLO_API_KEY=.*|APOLLO_API_KEY=$APOLLO_API_KEY|" .env
              else
                echo "APOLLO_API_KEY=$APOLLO_API_KEY" >> .env
              fi
            fi

            # Backend Python - force recreate venv to ensure correct Python version
            echo "=== Creating fresh Python venv ==="
            rm -rf venv
            python3 -m venv venv
            ./venv/bin/pip install -q --upgrade pip
            ./venv/bin/pip install -q -r requirements.txt

            # Backend Node.js
            echo "=== Installing Node.js backend ==="
            cd backend
            npm install --silent
            cd ..

            # Stop the services first
            echo "=== Stopping services ==="
            sudo systemctl stop scraping 2>/dev/null || true
            sudo systemctl stop scraping-backend 2>/dev/null || true
            pm2 stop all 2>/dev/null || true
            pm2 delete all 2>/dev/null || true

            # Create Python API systemd service
            echo "=== Creating Python API service ==="
            sudo tee /etc/systemd/system/scraping.service > /dev/null << 'SERVICE_EOF'
            [Unit]
            Description=Iconsai Scraping API (Python)
            After=network.target

            [Service]
            Type=simple
            User=root
            WorkingDirectory=/opt/iconsai-scraping
            EnvironmentFile=/opt/iconsai-scraping/.env
            ExecStart=/opt/iconsai-scraping/venv/bin/uvicorn api.main:app --host 0.0.0.0 --port 8000
            Restart=always

            [Install]
            WantedBy=multi-user.target
            SERVICE_EOF

            # Create Node.js backend systemd service
            echo "=== Creating Node.js backend service ==="
            sudo tee /etc/systemd/system/scraping-backend.service > /dev/null << 'SERVICE_EOF'
            [Unit]
            Description=Iconsai Scraping Backend (Node.js)
            After=network.target

            [Service]
            Type=simple
            User=root
            WorkingDirectory=/opt/iconsai-scraping/backend
            EnvironmentFile=/opt/iconsai-scraping/.env
            ExecStart=/usr/bin/node src/index.js
            Restart=always
            Environment=NODE_ENV=production
            Environment=BACKEND_PORT=3001

            [Install]
            WantedBy=multi-user.target
            SERVICE_EOF

            sudo systemctl daemon-reload
            sudo systemctl enable scraping
            sudo systemctl enable scraping-backend

            echo "=== Starting services ==="
            sudo systemctl start scraping
            sudo systemctl start scraping-backend
            sleep 3

            # Verify services
            echo "=== Services Status ==="
            sudo systemctl status scraping --no-pager || true
            sudo systemctl status scraping-backend --no-pager || true

            # Fix nginx configuration
            sudo tee /etc/nginx/sites-available/scraping-hub > /dev/null << 'NGINX_EOF'
            server {
                listen 80;
                server_name scraping.iconsai.ai;
                return 301 https://$server_name$request_uri;
            }
            server {
                listen 443 ssl http2;
                server_name scraping.iconsai.ai;
                ssl_certificate /etc/letsencrypt/live/scraping.iconsai.ai/fullchain.pem;
                ssl_certificate_key /etc/letsencrypt/live/scraping.iconsai.ai/privkey.pem;
                ssl_session_timeout 1d;
                ssl_session_cache shared:SSL:50m;
                ssl_protocols TLSv1.2 TLSv1.3;
                add_header Strict-Transport-Security "max-age=63072000" always;
                access_log /var/log/nginx/scraping-hub.access.log;
                error_log /var/log/nginx/scraping-hub.error.log;

                # Node.js backend API (port 3001)
                location /api/ {
                    proxy_pass http://127.0.0.1:3001/;
                    proxy_http_version 1.1;
                    proxy_set_header Host $host;
                    proxy_set_header X-Real-IP $remote_addr;
                    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                    proxy_set_header X-Forwarded-Proto $scheme;
                    proxy_read_timeout 300s;
                }

                # Python API (port 8000) - everything else
                location / {
                    proxy_pass http://127.0.0.1:8000;
                    proxy_http_version 1.1;
                    proxy_set_header Host $host;
                    proxy_set_header X-Real-IP $remote_addr;
                    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                    proxy_set_header X-Forwarded-Proto $scheme;
                    proxy_read_timeout 300s;
                }
            }
            NGINX_EOF

            # Enable site and reload nginx
            sudo ln -sf /etc/nginx/sites-available/scraping-hub /etc/nginx/sites-enabled/
            sudo rm -f /etc/nginx/sites-enabled/iconsai-scraping 2>/dev/null || true
            sudo nginx -t && sudo systemctl reload nginx

            echo "=== Git debug ==="
            git log --oneline -1
            git status
            echo ""
            echo "=== Directory listing ==="
            ls -la
            echo ""
            echo "=== Check if static exists in git ==="
            git ls-tree -r HEAD --name-only | grep static || echo "No static files in git tree!"
            echo ""
            echo "=== Static folder ==="
            ls -la static/ 2>/dev/null || echo "Static folder NOT FOUND"
            echo ""
            echo "=== Testing API ==="
            curl -s http://127.0.0.1:8000/health | head -c 200
            echo ""
            echo "=== Dashboard check ==="
            curl -s http://127.0.0.1:8000/dashboard | grep -o "Em desenvolvimento" | head -1 || echo "OLD VERSION - no 'Em desenvolvimento' found"
