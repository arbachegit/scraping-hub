# scraping-hub - Sistema de Web Scraping

**VERSÃƒO: 3.0.0 - COMPLIANCE + VALIDATION**
**DATA: 11/02/2026**
**STATUS: PROJETO AUDITADO - COMPLIANCE ISO 27001/27701**

---

## ğŸš¨ REGRAS IMUTÃVEIS (NUNCA VIOLAR)

### REGRA 0: PROIBIÃ‡ÃƒO ABSOLUTA DE MUDANÃ‡AS NÃƒO SOLICITADAS

```
âŒ NUNCA MUDAR CÃ“DIGO QUE NÃƒO FOI EXPLICITAMENTE PEDIDO
âŒ NUNCA "MELHORAR" CÃ“DIGO SEM AUTORIZAÃ‡ÃƒO
âŒ NUNCA "REFATORAR" SEM ORDEM DIRETA
âŒ NUNCA "OTIMIZAR" SEM PERMISSÃƒO
âŒ NUNCA ADICIONAR FEATURES NÃƒO PEDIDAS
âŒ NUNCA SUGERIR MUDANÃ‡AS - APENAS EXECUTAR ORDENS
```

**PENALIDADE:** Se Claude modificar QUALQUER arquivo nÃ£o solicitado, o trabalho Ã© REJEITADO e deve ser revertido completamente.

---

### REGRA 1: EXECUÃ‡ÃƒO LITERAL DE COMANDOS

**Claude deve:**
- âœ… Executar EXATAMENTE o que foi pedido
- âœ… NÃ£o interpretar, nÃ£o inferir, nÃ£o assumir
- âœ… Se houver QUALQUER ambiguidade â†’ PARAR e perguntar
- âœ… Confirmar entendimento ANTES de executar

**Formato obrigatÃ³rio de resposta:**
```
Entendi que vocÃª quer:
1. [aÃ§Ã£o especÃ­fica 1]
2. [aÃ§Ã£o especÃ­fica 2]
3. [aÃ§Ã£o especÃ­fica 3]

Arquivos que serÃ£o modificados:
- arquivo1.py (linha X-Y)
- arquivo2.py (adicionar funÃ§Ã£o Z)

CONFIRMAÃ‡ÃƒO NECESSÃRIA: Prosseguir? (sim/nÃ£o)
```

---

### REGRA 2: VALIDAÃ‡ÃƒO OBRIGATÃ“RIA (ZOD + PYDANTIC)

**Todo endpoint DEVE ter validaÃ§Ã£o:**

```javascript
// âœ… Node.js - SEMPRE usar Zod
import { z } from 'zod';
import { validateBody } from '../validation/schemas.js';

const schema = z.object({
  nome: z.string().min(2).max(200),
  cnpj: z.string().transform(val => val.replace(/[^\d]/g, ''))
});

router.post('/endpoint', validateBody(schema), async (req, res) => {
  // req.body jÃ¡ validado
});
```

```python
# âœ… Python - SEMPRE usar Pydantic
from pydantic import BaseModel

class RequestBody(BaseModel):
    nome: str
    cnpj: str

@app.post("/endpoint")
async def endpoint(body: RequestBody):
    # body jÃ¡ validado
```

**Schemas existentes:** `backend/src/validation/schemas.js`
- `searchCompanySchema` - Busca de empresa
- `detailsCompanySchema` - Detalhes por CNPJ
- `sociosSchema` - Enriquecimento de sÃ³cios
- `approveCompanySchema` - AprovaÃ§Ã£o de empresa
- `recalculateSchema` - RecÃ¡lculo VAR

---

### REGRA 3: CONSTANTES OBRIGATÃ“RIAS (SEM MAGIC STRINGS)

**NUNCA usar strings literais repetidas:**

```javascript
// âŒ PROIBIDO
linkedin = 'NAO_POSSUI';
regime = 'SIMPLES_NACIONAL';

// âœ… OBRIGATÃ“RIO - usar constants.js
import { LINKEDIN_STATUS, REGIME_TRIBUTARIO } from '../constants.js';

linkedin = LINKEDIN_STATUS.NAO_POSSUI;
regime = REGIME_TRIBUTARIO.SIMPLES_NACIONAL;
```

**Constantes disponÃ­veis:** `backend/src/constants.js`
- `LINKEDIN_STATUS` - NAO_POSSUI, PENDENTE
- `REGIME_TRIBUTARIO` - MEI, SIMPLES_NACIONAL, LUCRO_PRESUMIDO, LUCRO_REAL
- `LIMITES_REGIME` - Limites de faturamento por regime
- `DATA_SOURCES` - Fontes de dados para compliance

---

### REGRA 4: LOGGING ESTRUTURADO OBRIGATÃ“RIO

**NUNCA usar console.log para logs de produÃ§Ã£o:**

```javascript
// âŒ PROIBIDO
console.log('Buscando empresa:', nome);
console.error('Erro:', error);

// âœ… OBRIGATÃ“RIO - usar logger estruturado
import logger from '../utils/logger.js';

logger.info('Buscando empresa', { nome, cidade });
logger.error('Erro na busca', { error: error.message, stack: error.stack });
```

**Logger:** `backend/src/utils/logger.js`
- Formato JSON estruturado
- NÃ­veis: debug, info, warn, error
- Request ID para rastreamento
- Consistente com Python structlog

---

### REGRA 5: RATE LIMITER OBRIGATÃ“RIO

**Todo endpoint pÃºblico DEVE ter rate limit:**

```javascript
// Configurado em backend/src/index.js
import rateLimit from 'express-rate-limit';

const limiter = rateLimit({
  windowMs: 60 * 1000,  // 1 minuto
  max: 100,             // 100 requisiÃ§Ãµes por IP
  message: { error: 'Muitas requisiÃ§Ãµes. Tente novamente em 1 minuto.' }
});

app.use('/companies', limiter);
```

**Limites atuais:**
- `/companies/*` - 100 req/min por IP

---

### REGRA 6: REGISTRO DE FONTES OBRIGATÃ“RIO (COMPLIANCE)

**TODO scraping DEVE registrar fonte na tabela `fontes_dados`:**

```javascript
// Registro automÃ¡tico no startup do backend
import { registerDataSource } from '../database/supabase.js';
import { DATA_SOURCES } from '../constants.js';

// Auto-registro de todas as fontes
for (const [key, source] of Object.entries(DATA_SOURCES)) {
  await registerDataSource(source);
}
```

**Tabela `fontes_dados` (Supabase):**
| Campo | Tipo | ObrigatÃ³rio |
|-------|------|-------------|
| nome | TEXT UNIQUE | âœ… |
| categoria | TEXT | âœ… |
| fonte_primaria | TEXT | âœ… |
| url | TEXT | âœ… |
| confiabilidade | TEXT | âœ… |
| api_key_necessaria | BOOLEAN | âœ… |

**Fontes registradas:**
1. Serper - Google Search API (busca)
2. Perplexity AI (ia)
3. BrasilAPI - Receita Federal (governamental)
4. Apollo.io (enrichment)
5. CNPJÃ¡ - Regime TributÃ¡rio (fiscal)

**Penalidade:** Scraper sem registro de fonte = REJEITADO

---

### REGRA 7: IMUTABILIDADE DO BASE.PY

**O arquivo `src/scrapers/base.py` Ã© SAGRADO:**

```
ğŸ”’ NUNCA modificar base.py sem ordem EXPLÃCITA
ğŸ”’ NUNCA "melhorar" base.py
ğŸ”’ NUNCA "otimizar" base.py
ğŸ”’ NUNCA adicionar features a base.py

âœ… APENAS criar NOVOS scrapers que HERDAM de BaseScraper
```

---

### REGRA 8: SCRAPERS SÃƒO WRITE-ONLY

**Scrapers existentes NÃƒO podem ser modificados:**

```
ğŸ”’ src/scrapers/*.py     - IMUTÃVEL
ğŸ”’ backend/src/services/*.js - IMUTÃVEL (exceto bug fixes)
```

**Ãšnico caso permitido para modificaÃ§Ã£o:**
```
"Corrija o BUG na linha X do arquivo Y"
"Adicione o parÃ¢metro Z Ã  funÃ§Ã£o W do arquivo V"
```

---

### REGRA 9: DEPLOY VIA CI/CD (GITHUB ACTIONS)

**NUNCA fazer deploy manual:**

```
âŒ NUNCA SSH no servidor para deploy
âŒ NUNCA editar arquivos diretamente no servidor
âŒ NUNCA rodar comandos manuais no servidor

âœ… SEMPRE commit + push â†’ CI/CD automÃ¡tico
âœ… SEMPRE usar GitHub Actions
âœ… SEMPRE secrets via GitHub Secrets
```

**Secrets configurados:**
- `DO_HOST` - IP do servidor
- `DO_USERNAME` - UsuÃ¡rio SSH
- `DO_SSH_KEY` - Chave SSH
- `APOLLO_API_KEY` - Apollo API
- `CNPJA_API_KEY` - CNPJÃ¡ API
- `PERPLEXITY_API_KEY` - Perplexity API

---

## ğŸ“ ESTRUTURA DO PROJETO

```
scraping-hub/
â”œâ”€â”€ .claude/
â”‚   â””â”€â”€ CLAUDE.md                    ğŸ“‹ Este arquivo
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.js                 ğŸš€ Entry point (rate limiter, logger)
â”‚   â”‚   â”œâ”€â”€ constants.js             ğŸ“Œ Constantes (LINKEDIN_STATUS, etc)
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â””â”€â”€ companies.js         ğŸ›£ï¸ Rotas (com Zod validation)
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ serper.js            ğŸ” Google Search
â”‚   â”‚   â”‚   â”œâ”€â”€ perplexity.js        ğŸ¤– AI Search (fallback)
â”‚   â”‚   â”‚   â”œâ”€â”€ apollo.js            ğŸ‘¤ LinkedIn enrichment
â”‚   â”‚   â”‚   â”œâ”€â”€ brasilapi.js         ğŸ›ï¸ Receita Federal
â”‚   â”‚   â”‚   â”œâ”€â”€ cnpja.js             ğŸ“Š Regime tributÃ¡rio
â”‚   â”‚   â”‚   â””â”€â”€ var_inference.js     ğŸ“ˆ Modelo VAR
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”‚   â””â”€â”€ supabase.js          ğŸ—„ï¸ DB + registerDataSource
â”‚   â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”‚   â””â”€â”€ schemas.js           âœ… Zod schemas
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ logger.js            ğŸ“ Structured logging
â”‚   â””â”€â”€ database/
â”‚       â””â”€â”€ migrations/              ğŸ”„ SQL migrations
â”œâ”€â”€ src/
â”‚   â””â”€â”€ scrapers/
â”‚       â””â”€â”€ base.py                  ğŸ”’ IMUTÃVEL
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                      ğŸ FastAPI
â”‚   â””â”€â”€ auth.py                      ğŸ” JWT + Pydantic
â”œâ”€â”€ static/
â”‚   â””â”€â”€ dashboard.html               ğŸ–¥ï¸ Frontend
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ apply_migration_*.py         ğŸ”§ Migration scripts
â”œâ”€â”€ tests/                           ğŸ§ª Pytest
â””â”€â”€ .github/workflows/
    â””â”€â”€ ci.yml                       ğŸš€ CI/CD
```

---

## ğŸ”„ FLUXO DE BUSCA (FALLBACK)

```
1. Serper (Google)
   â†“ nÃ£o encontrou?
2. Perplexity AI
   â†“ nÃ£o encontrou?
3. Serper (nome exato)
   â†“ nÃ£o encontrou?
4. Retorna vazio + sources_tried
```

---

## ğŸ—„ï¸ BANCO DE DADOS (SUPABASE)

**Tabelas principais:**
- `dim_empresas` - Dados cadastrais
- `dim_pessoas` - SÃ³cios/fundadores
- `fato_regime_tributario` - HistÃ³rico de regimes
- `fato_transacao_empresas` - RelaÃ§Ã£o pessoa-empresa
- `fato_inferencia_limites` - AnÃ¡lise VAR
- `fontes_dados` - Compliance (ISO 27001/27701)

---

## ğŸš€ COMANDOS

```bash
# Deploy (via CI/CD)
git add . && git commit -m "feat: ..." && git push

# Rodar testes
pytest tests/ -v

# Rodar backend local
cd backend && npm run dev

# Rodar Python API local
uvicorn api.main:app --reload
```

---

## ğŸ“ CHANGELOG

**v3.0.0 (11/02/2026) - COMPLIANCE + VALIDATION**
- âœ… ValidaÃ§Ã£o Zod em todos os endpoints Node.js
- âœ… Rate limiter (100 req/min)
- âœ… Logging estruturado (JSON)
- âœ… Constantes (sem magic strings)
- âœ… Tabela fontes_dados (compliance ISO 27001/27701)
- âœ… Auto-registro de fontes no startup
- âœ… Removida dependÃªncia de DigitalOcean API direta

**v2.0.0 (08/02/2026) - ULTRA-STRICT**
- âœ… ProibiÃ§Ã£o absoluta de mudanÃ§as nÃ£o solicitadas
- âœ… Imutabilidade de base.py e scrapers existentes
- âœ… Testes automÃ¡ticos obrigatÃ³rios
- âœ… CI/CD automÃ¡tico obrigatÃ³rio

---

**ESTE DOCUMENTO Ã‰ A FONTE DA VERDADE**
**VIOLAÃ‡Ã•ES SERÃƒO REJEITADAS**
